{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from scipy.stats import mannwhitneyu, entropy, kstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '4'\n",
    "os.environ['NUM_WORKERS'] = '4'\n",
    "os.environ['MKL_NUM_THREADS'] = '4'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/HlabShare/sleep_dcc_yifan/final_production/Source Data\n"
     ]
    }
   ],
   "source": [
    "cd /media/HlabShare/sleep_dcc_yifan/final_production/Source\\ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>perc_sleep</th>\n",
       "      <th>DCC</th>\n",
       "      <th>T4</th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>CV</th>\n",
       "      <th>FR</th>\n",
       "      <th>ZT</th>\n",
       "      <th>SWA</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XYF06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119316</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.299105</td>\n",
       "      <td>0.960447</td>\n",
       "      <td>13</td>\n",
       "      <td>0.757911</td>\n",
       "      <td>1.911381</td>\n",
       "      <td>2.355457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XYF06</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>0.226115</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417778</td>\n",
       "      <td>0.208889</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.331130</td>\n",
       "      <td>1.097994</td>\n",
       "      <td>15</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>1.958712</td>\n",
       "      <td>2.345246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XYF06</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.180043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417778</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>0.914444</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.274289</td>\n",
       "      <td>0.792273</td>\n",
       "      <td>17</td>\n",
       "      <td>0.910909</td>\n",
       "      <td>2.355083</td>\n",
       "      <td>2.760575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XYF06</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.778889</td>\n",
       "      <td>0.914444</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.278889</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.318826</td>\n",
       "      <td>0.987282</td>\n",
       "      <td>19</td>\n",
       "      <td>0.752604</td>\n",
       "      <td>2.122211</td>\n",
       "      <td>2.614125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XYF06</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.192556</td>\n",
       "      <td>0.176667</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.266260</td>\n",
       "      <td>0.911802</td>\n",
       "      <td>21</td>\n",
       "      <td>0.962503</td>\n",
       "      <td>2.229426</td>\n",
       "      <td>2.794184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal  perc_sleep       DCC        T4        T3        T2        T1  \\\n",
       "1  XYF06    0.000000  0.119316  0.733333  0.313333  0.583333  0.507778   \n",
       "2  XYF06    0.778889  0.226115  0.583333  0.507778  0.000000  0.417778   \n",
       "3  XYF06    0.176667  0.180043  0.000000  0.417778  0.778889  0.914444   \n",
       "4  XYF06    0.813333  0.107884  0.778889  0.914444  0.176667  0.381111   \n",
       "5  XYF06    0.317778  0.192556  0.176667  0.381111  0.813333  0.856667   \n",
       "\n",
       "   Behavior  cat1  cat2        CV        FR  ZT       SWA     Alpha      Beta  \n",
       "1  0.545556     0     0  1.299105  0.960447  13  0.757911  1.911381  2.355457  \n",
       "2  0.208889     1     3  1.331130  1.097994  15  0.971613  1.958712  2.345246  \n",
       "3  0.846667     0     0  1.274289  0.792273  17  0.910909  2.355083  2.760575  \n",
       "4  0.278889     1     3  1.318826  0.987282  19  0.752604  2.122211  2.614125  \n",
       "5  0.835000     0     1  1.266260  0.911802  21  0.962503  2.229426  2.794184  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Source data Fig 2.xlsx',engine='openpyxl')\n",
    "df = df[(df['perc_sleep']<=0.33)|(df['perc_sleep']>=0.66)] #filter line \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_splits(data_df,class_balance=True,class_col='cat1',test_size=0.15,n_splits=10):\n",
    "    if class_balance == True:\n",
    "        data_df = data_df.groupby(class_col)\n",
    "        data_df = data_df.apply(lambda x: x.sample(data_df.size().min(), random_state=42).reset_index(drop=True))\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
    "    split_idxs = sss.split(data_df, data_df[class_col])\n",
    "    return data_df, split_idxs\n",
    "\n",
    "def train_val_test_splits(data_df,class_balance=True,class_col='cat1',test_size=0.1,val_size=0.1,n_splits=10,random_state=42):\n",
    "    if class_balance == True:\n",
    "        data_df = data_df.groupby(class_col)\n",
    "        data_df = data_df.apply(lambda x: x.sample(data_df.size().min(), random_state=random_state).reset_index(drop=True))\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    split_idxs = sss.split(data_df, data_df[class_col])\n",
    "    train_idxs, test_idxs, val_idxs = [],[],[]\n",
    "    for train,test in split_idxs:\n",
    "        test_idxs.append(test)\n",
    "        train_df = data_df.iloc[train]\n",
    "        train_labels = data_df.iloc[train][class_col]\n",
    "        if val_size == test_size:\n",
    "            sss2 = StratifiedShuffleSplit(n_splits=1, test_size=len(test)/len(train), random_state=42)\n",
    "            split_idxs2 = sss2.split(train_df,train_labels)\n",
    "            for train2,val in split_idxs2:\n",
    "                train_idxs.append(train[train2])\n",
    "                val_idxs.append(train[val])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    split_idxs = zip(train_idxs,val_idxs,test_idxs)\n",
    "    return data_df, split_idxs\n",
    "\n",
    "\n",
    "def train_classifiers(data_df, model, split_idxs, model_kwargs = None, feature_cols=['T1','T2','T3','T4','CT'], class_col='cat1'):\n",
    "    models = []\n",
    "    for train_idxs, test_idxs in split_idxs:\n",
    "        if model == 'random_forest':\n",
    "            if model_kwargs is None:\n",
    "                iter_model = RandomForestClassifier(random_state=42)\n",
    "            else:\n",
    "                iter_model = RandomForestClassifier(random_state=42,**model_kwargs)\n",
    "        elif model == 'logistic_regression':\n",
    "            if model_kwargs is None:\n",
    "                iter_model = LogisticRegression(random_state=69)\n",
    "            else:\n",
    "                iter_model = LogisticRegression(random_state=69,**model_kwargs)\n",
    "        elif model == 'xgboost':\n",
    "            if model_kwargs is None:\n",
    "                iter_model = XGBClassifier(random_state=42)\n",
    "            else:\n",
    "                iter_model = XGBClassifier(random_state=42,**model_kwargs)\n",
    "        x = data_df.iloc[train_idxs][feature_cols]\n",
    "        y = data_df.iloc[train_idxs][class_col]\n",
    "        iter_model.fit(x,y)\n",
    "        models.append(iter_model)\n",
    "    return models\n",
    "\n",
    "def eval_classifiers(data_df, models, split_idxs, evaluator, eval_set='test',feature_cols=['T1','T2','T3','T4','CT'], class_col='cat1'):\n",
    "    metrics = []\n",
    "    for iter_,(train_idxs, test_idxs) in enumerate(split_idxs):\n",
    "        model = models[iter_]\n",
    "        if eval_set == 'test':\n",
    "            x = data_df.iloc[test_idxs][feature_cols]\n",
    "            y = data_df.iloc[test_idxs][class_col]\n",
    "        elif eval_set == 'train':\n",
    "            x = data_df.iloc[train_idxs][feature_cols]\n",
    "            y = data_df.iloc[train_idxs][class_col]\n",
    "        y_ = model.predict(x)\n",
    "        metric = evaluator(y,y_)\n",
    "        metrics.append(metric)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Models (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = 'logistic_regression'\n",
    "\n",
    "evaluator = accuracy_score\n",
    "feature_cols_lol = [['Behavior'],['ZT'],['FR'],['CV'],['SWA'],['DCC']]\n",
    "\n",
    "class_col = 'cat1'\n",
    "n_splits= 100\n",
    "test_size = 0.22\n",
    "class_balance = True\n",
    "random_state = 42\n",
    "\n",
    "model_kwargs = None\n",
    "train_metrics_means, test_metrics_means = [],[]\n",
    "test_results_by_feature_dict = {}\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for feature_cols in feature_cols_lol:\n",
    "    data_df, split_idxs = train_test_splits(df, class_balance=class_balance, class_col=class_col, test_size=test_size, n_splits=n_splits)\n",
    "    classifiers = train_classifiers(data_df, model, split_idxs, model_kwargs, feature_cols=feature_cols, class_col=class_col)\n",
    "    \n",
    "    data_df, split_idxs = train_test_splits(df, class_balance=class_balance, class_col=class_col, test_size=test_size, n_splits=n_splits)\n",
    "    train_metrics = eval_classifiers(data_df, classifiers, split_idxs, evaluator, eval_set='train',feature_cols=feature_cols, class_col=class_col)\n",
    "    \n",
    "    data_df, split_idxs = train_test_splits(df, class_balance=class_balance, class_col=class_col, test_size=test_size, n_splits=n_splits)\n",
    "    test_metrics = eval_classifiers(data_df, classifiers, split_idxs, evaluator, eval_set='test',feature_cols=feature_cols, class_col=class_col)\n",
    "    #print(np.mean(train_metrics),\"+\\-\",stats.sem(train_metrics),np.mean(test_metrics),\"+\\-\",stats.sem(test_metrics))\n",
    "    test_results_by_feature_dict[feature_cols[0]] = [np.mean(train_metrics),stats.sem(test_metrics),np.mean(test_metrics),stats.sem(test_metrics)]\n",
    "    test_results.append(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({'behavior':test_results[0],\n",
    "                   'ZT':test_results[1],'FR':test_results[2],'CV':test_results[3],\n",
    "                   'SWA':test_results[4],'DCC':test_results[5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hyperparameter Tuning (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_splits(data_df,class_balance=True,class_col='cat1',test_size=0.1,val_size=0.1,n_splits=10,random_state=42):\n",
    "    if class_balance == True:\n",
    "        data_df = data_df.groupby(class_col)\n",
    "        data_df = data_df.apply(lambda x: x.sample(data_df.size().min(), random_state=random_state).reset_index(drop=True))\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    split_idxs = sss.split(data_df, data_df[class_col])\n",
    "    train_idxs, test_idxs, val_idxs = [],[],[]\n",
    "    for train,test in split_idxs:\n",
    "        test_idxs.append(test)\n",
    "        train_df = data_df.iloc[train]\n",
    "        train_labels = data_df.iloc[train][class_col]\n",
    "        if val_size == test_size:\n",
    "            sss2 = StratifiedShuffleSplit(n_splits=1, test_size=len(test)/len(train), random_state=42)\n",
    "            split_idxs2 = sss2.split(train_df,train_labels)\n",
    "            for train2,val in split_idxs2:\n",
    "                train_idxs.append(train[train2])\n",
    "                val_idxs.append(train[val])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    split_idxs = zip(train_idxs,val_idxs,test_idxs)\n",
    "    return data_df, split_idxs\n",
    "\n",
    "\n",
    "def train_classifiers(data_df, model, split_idxs, model_kwargs = None, feature_cols=['T1','T2','T3','T4','CT'], class_col='cat1'):\n",
    "    models = []\n",
    "    for train_idxs, val_idxs, test_idxs in split_idxs:\n",
    "        if model == 'random_forest':\n",
    "            if model_kwargs is None:\n",
    "                iter_model = RandomForestClassifier(random_state=42)\n",
    "            else:\n",
    "                iter_model = RandomForestClassifier(random_state=42,**model_kwargs)\n",
    "        elif model == 'logistic_regression':\n",
    "            if model_kwargs is None:\n",
    "                iter_model = LogisticRegression(random_state=69)\n",
    "            else:\n",
    "                iter_model = LogisticRegression(random_state=69,**model_kwargs)\n",
    "        elif model == 'xgboost':\n",
    "            if model_kwargs is None:\n",
    "                iter_model = XGBClassifier(random_state=42)\n",
    "            else:\n",
    "                iter_model = XGBClassifier(random_state=42,**model_kwargs)\n",
    "        x = data_df.iloc[train_idxs][feature_cols]\n",
    "        y = data_df.iloc[train_idxs][class_col]\n",
    "        iter_model.fit(x,y)\n",
    "        models.append(iter_model)\n",
    "    return models\n",
    "\n",
    "def eval_classifiers(data_df, models, split_idxs, evaluator, eval_set='test',feature_cols=['T1','T2','T3','T4','CT'], class_col='cat1'):\n",
    "    metrics = []\n",
    "    for iter_,(train_idxs, val_idxs, test_idxs) in enumerate(split_idxs):\n",
    "        model = models[iter_]\n",
    "        if eval_set == 'test':\n",
    "            x = data_df.iloc[test_idxs][feature_cols]\n",
    "            y = data_df.iloc[test_idxs][class_col]\n",
    "        elif eval_set == 'train':\n",
    "            x = data_df.iloc[train_idxs][feature_cols]\n",
    "            y = data_df.iloc[train_idxs][class_col]\n",
    "        y_ = model.predict(x)\n",
    "        metric = evaluator(y,y_)\n",
    "        metrics.append(metric)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    data_df,split_idxs = train_val_test_splits(df,class_balance=class_balance,class_col=class_col,test_size=0.1,n_splits=n_splits)\n",
    "    val_metrics, test_metrics = [],[]\n",
    "    for train_idxs, val_idxs, test_idxs in split_idxs:\n",
    "        iter_model = XGBClassifier(\n",
    "        learning_rate = space['learning_rate'],\n",
    "        n_estimators = int(space['n_estimators']),\n",
    "        max_depth = int(space['max_depth']),\n",
    "        #gamma = space['gamma'],\n",
    "        reg_alpha = space['reg_alpha'],\n",
    "        reg_lambda = space['reg_lambda'],\n",
    "        random_state = int(space['random_state'])\n",
    "        )\n",
    "        x = data_df.iloc[train_idxs][feature_cols]\n",
    "        y = data_df.iloc[train_idxs][class_col]\n",
    "        iter_model.fit(x,y)\n",
    "        \n",
    "        x2 = data_df.iloc[val_idxs][feature_cols]\n",
    "        y2 = data_df.iloc[val_idxs][class_col]\n",
    "        y2_ = iter_model.predict(x2)\n",
    "        val_metric = evaluator(y2,y2_) #evaluator defined in global scope\n",
    "        val_metrics.append(val_metric)\n",
    "\n",
    "        x3 = data_df.iloc[test_idxs][feature_cols]\n",
    "        y3 = data_df.iloc[test_idxs][class_col]\n",
    "        y3_ = iter_model.predict(x3)\n",
    "        test_metric = evaluator(y3,y3_)\n",
    "        test_metrics.append(test_metric)\n",
    "\n",
    "    metric = -1 * np.mean(val_metrics)\n",
    "    #print('SCORES:', np.mean(val_metrics), np.mean(test_metrics))\n",
    "    return {'loss': metric, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'xgboost'\n",
    "evaluator = balanced_accuracy_score\n",
    "feature_cols =['Behavior','ZT']\n",
    "class_col = 'cat1'\n",
    "n_splits= 20\n",
    "test_size = 0.1\n",
    "class_balance = False\n",
    "\n",
    "\n",
    "space={'learning_rate': hp.uniform('learning_rate',1E-1,1E4),\n",
    "      'n_estimators': hp.quniform('n_estimators',1,1000,5),\n",
    "       'max_depth': hp.quniform('max_depth',1,10,1),\n",
    "       'gamma': hp.quniform('gamma',0,0.1,0.01),\n",
    "       'reg_alpha': hp.uniform('reg_alpha',0,20),\n",
    "       'reg_lambda': hp.uniform('reg_lambda',0,100000000),\n",
    "       'random_state': 42 \n",
    "      }\n",
    "\n",
    "trials = Trials()\n",
    "base_best_hyperparams = fmin(fn = objective,\n",
    "                       space = space,\n",
    "                       algo = tpe.suggest,\n",
    "                       max_evals = 1000,\n",
    "                       trials = trials)\n",
    "print(base_best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use hyperparams to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'xgboost'\n",
    "evaluator = balanced_accuracy_score\n",
    "class_col = 'cat1'\n",
    "n_splits= 200\n",
    "test_size = 0.2\n",
    "class_balance = False\n",
    "\n",
    "#OPTIMAL HYPERPARAMETERS\n",
    "\n",
    "base_hps = {#'gamma': 0.05,\n",
    " 'learning_rate': 3687.1577557642274,\n",
    " 'max_depth': int(2.0),\n",
    " 'n_estimators': int(200.0),\n",
    " 'reg_alpha': 0.644242525839416312,\n",
    " 'reg_lambda': 1990899.2470538504}\n",
    "\n",
    "fr_hps = {#'gamma': 0.01,\n",
    " 'learning_rate': 3991.228385329264,\n",
    " 'max_depth': int(2.0),\n",
    " 'n_estimators': int(435.0),\n",
    " 'reg_alpha': 1.967722248935879,\n",
    " 'reg_lambda': 137488.76528007258}\n",
    "\n",
    "cv_hps = {#'gamma': 0.07,\n",
    " 'learning_rate': 7398.910949037821,\n",
    " 'max_depth': int(3.0),\n",
    " 'n_estimators': int(500.0),\n",
    " 'reg_alpha': 1.5460545805746793,\n",
    " 'reg_lambda': 220523.1005840188}\n",
    "    \n",
    "dcc_hps = {# 'gamma': 0.1,\n",
    " 'learning_rate': 3549.976010895837,\n",
    " 'max_depth': int(2.0),\n",
    " 'n_estimators': int(400.0),\n",
    " 'reg_alpha': 1.11745609628605068,\n",
    " 'reg_lambda': 1955442.3496703221}\n",
    "\n",
    "all_hps = {#'gamma': 0.1,\n",
    " 'learning_rate': 4195.186967321277,\n",
    " 'max_depth': int(2.0),\n",
    " 'n_estimators': int(530.0),\n",
    " 'reg_alpha': 0.3924498620840177,\n",
    " 'reg_lambda': 1819330.6569741974}\n",
    "\n",
    "hp_dicts_list = [dcc_hps]\n",
    "\n",
    "feature_cols_list = [['DCC','Behavior','ZT']]\n",
    "\n",
    "\n",
    "for hps,feature_cols in zip(hp_dicts_list,feature_cols_list):\n",
    "    \n",
    "    # data_df,split_idxs = train_val_test_splits(df,class_balance=class_balance,class_col=class_col,test_size=test_size,val_size=test_size,n_splits=n_splits)\n",
    "    data_df, split_idxs = train_test_splits(df, class_balance=class_balance, class_col=class_col, test_size=test_size, n_splits=n_splits)\n",
    "    classifiers = train_classifiers(data_df, model, split_idxs, model_kwargs=hps, feature_cols=feature_cols, class_col=class_col)\n",
    "    \n",
    "    data_df,split_idxs = train_test_splits(df, class_balance=class_balance, class_col=class_col, test_size=test_size, n_splits=n_splits)\n",
    "    train_metrics = eval_classifiers(data_df, classifiers, split_idxs, evaluator, eval_set='train',feature_cols=feature_cols, class_col=class_col)\n",
    "    \n",
    "    data_df,split_idxs = train_test_splits(df, class_balance=class_balance, class_col=class_col, test_size=test_size, n_splits=n_splits)\n",
    "    test_metrics = eval_classifiers(data_df, classifiers, split_idxs, evaluator, eval_set='test',feature_cols=feature_cols, class_col=class_col)\n",
    "    \n",
    "    print(train_metrics,test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_hps = {#'gamma': 0.1,\n",
    " 'learning_rate': 4195.186967321277,\n",
    " 'max_depth': int(2.0),\n",
    " 'n_estimators': int(730.0),\n",
    " 'reg_alpha': 0.3924498620840177,\n",
    " 'reg_lambda': 1819330.6569741974}\n",
    "\n",
    "feat_imps = []\n",
    "for classifier in classifiers:\n",
    "    feat_imps.append(classifier.feature_importances_)\n",
    "feat_imps_arr = np.vstack(feat_imps)\n",
    "mean_feat_imps = np.mean(feat_imps_arr,axis=0)\n",
    "std_feat_imps = stats.sem(feat_imps_arr,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check the order!\n",
    "\n",
    "importance = pd.DataFrame({'Behavior':feat_imps_arr[:,0],'ZT':feat_imps_arr[:,1],'SWA':feat_imps_arr[:,2],'FR':feat_imps_arr[:,3]\n",
    "                          ,'CV':feat_imps_arr[:,4],'DCC':feat_imps_arr[:,5]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Behavior</th>\n",
       "      <th>CT</th>\n",
       "      <th>SWA</th>\n",
       "      <th>FR</th>\n",
       "      <th>CV</th>\n",
       "      <th>DCC</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.198631</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.107817</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.261559</td>\n",
       "      <td>0.088350</td>\n",
       "      <td>0.071320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.037176</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.011441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.141823</td>\n",
       "      <td>0.083017</td>\n",
       "      <td>0.051023</td>\n",
       "      <td>0.077092</td>\n",
       "      <td>0.049186</td>\n",
       "      <td>0.174056</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>0.043161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.178970</td>\n",
       "      <td>0.109846</td>\n",
       "      <td>0.066355</td>\n",
       "      <td>0.099115</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.237331</td>\n",
       "      <td>0.077414</td>\n",
       "      <td>0.062967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.197899</td>\n",
       "      <td>0.121784</td>\n",
       "      <td>0.071959</td>\n",
       "      <td>0.108034</td>\n",
       "      <td>0.073501</td>\n",
       "      <td>0.257071</td>\n",
       "      <td>0.086739</td>\n",
       "      <td>0.070160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.215796</td>\n",
       "      <td>0.134286</td>\n",
       "      <td>0.079466</td>\n",
       "      <td>0.116185</td>\n",
       "      <td>0.083997</td>\n",
       "      <td>0.281693</td>\n",
       "      <td>0.096128</td>\n",
       "      <td>0.080246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.275412</td>\n",
       "      <td>0.183010</td>\n",
       "      <td>0.106074</td>\n",
       "      <td>0.146431</td>\n",
       "      <td>0.132051</td>\n",
       "      <td>0.394391</td>\n",
       "      <td>0.130438</td>\n",
       "      <td>0.101976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Behavior          CT         SWA          FR          CV         DCC  \\\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000  200.000000   \n",
       "mean     0.198631    0.123702    0.073256    0.107817    0.075365    0.261559   \n",
       "std      0.027977    0.017883    0.009692    0.012833    0.013411    0.037176   \n",
       "min      0.141823    0.083017    0.051023    0.077092    0.049186    0.174056   \n",
       "25%      0.178970    0.109846    0.066355    0.099115    0.066218    0.237331   \n",
       "50%      0.197899    0.121784    0.071959    0.108034    0.073501    0.257071   \n",
       "75%      0.215796    0.134286    0.079466    0.116185    0.083997    0.281693   \n",
       "max      0.275412    0.183010    0.106074    0.146431    0.132051    0.394391   \n",
       "\n",
       "            Alpha        Beta  \n",
       "count  200.000000  200.000000  \n",
       "mean     0.088350    0.071320  \n",
       "std      0.013596    0.011441  \n",
       "min      0.057322    0.043161  \n",
       "25%      0.077414    0.062967  \n",
       "50%      0.086739    0.070160  \n",
       "75%      0.096128    0.080246  \n",
       "max      0.130438    0.101976  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
